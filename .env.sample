# ===========================================
# Crisis Intelligence Pipeline Configuration
# ===========================================

# LLM Provider API Keys
OPENAI_API_KEY=sk-your-openai-key-here
GEMINI_API_KEY=your-gemini-key-here
GROQ_API_KEY=your-groq-key-here

# Default Model Configuration
DEFAULT_PROVIDER=google
DEFAULT_MODEL=gemini-2.0-flash-exp

# Alternative Models
# DEFAULT_MODEL=gpt-4o-mini  # For OpenAI
# DEFAULT_MODEL=llama-3.1-8b-instant  # For Groq

# Application Settings
LOG_DIR=logs
LOG_FILE=runs.csv
OUTPUT_DIR=output

# Token Budget (for Part 4)
MAX_MESSAGE_TOKENS=150
```

4. Commit message: `config: Add environment configuration template`
5. Extended description:
```
Provide .env.sample for easy setup:
- API key placeholders for all three providers
- Default model selection (Gemini)
- Alternative model options documented
- Token budget configuration for cost control
- Log and output directory settings
